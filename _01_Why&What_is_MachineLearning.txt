>> Machine Learning:
    A field of computer that uses statistical techniques to give computer systems the ability to learn with data without being explicitly programmed. 

>> AI vs ML vs DL:
    - AI: A broad field that includes both machine learning and deep learning. It is a subset of computer science that focuses on creating intelligent machines capable of performing tasks that typically require human intelligence.
    - ML: A subset of AI that involves training algorithms to make predictions or decisions based on data.
    - DL: A subset of ML that uses neural networks with multiple layers to analyze data and make predictions or decisions.

>> Types of ML based on supervision:
    - Supervised Learning: The algorithm is trained on labeled data to make predictions.
        Regression : Predicts a continuous value.
        Classification : Predicts a categorical value.

    - Unsupervised Learning: The algorithm is trained on unlabeled data to identify patterns.
        Clusturing : Groups similar data points together.
        Dimensionality Reduction : Reduces the number of features in the data.
        Anamoly Detection : Identifies data points that are different from the rest.
        Assosiation Rule Mining : Finds relationships between data points.
        
    - semi-Supervised Learning: The algorithm is trained on a combination of labeled and unlabeled data.
    - Reinforcement Learning: The algorithm learns by interacting with an environment and receiving rewards or penalties.

>> Types of machine learning based on production:
    - Online Learning: The algorithm is trained on a stream of data. (data is feeded sequencely mini batch wise and It learns/improve on the go while using the ML model on server)
    - Batch or Offline Learning: The algorithm is trained on a fixed dataset. working large amount of data, First train with data offline then deploy over servers.

    >> Offline Learning: 
        - Problem with Batch Learning: 
            The algorithm may not perform well on new data that is not in the training set. 
            We have to update the model with new data to keep it up to date, which can be time-consuming and expensive.

        - Disadvantage of Batch ML:
            1. Lots of data 
            2. Hardware Limitation 
            3. Avalibility of data (data is not available at the time of training)
        
        - When to use Batch Learning:
            1. When the data is not changing frequently.
            2. When the data is not available in real-time.
            3. When the data is too large to be processed in real-time.

    >> Online Learning:        
        - When to use online learning:
            1. Where there is concept drift (data distribution changes over time)
            2. Cost effective (no need to store large amount of data)
            3. Real time prediction (e.g. stock prices, weather forecast)
            4. Faster Solution

        - Disadvantage:
            1. Tricky to use (need to handle concept drift)
            2. Risky (if the model is not good, it can lead to poor performance)

        - Learning Rate : The rate at which the algorithm learns from the data. A high learning rate can lead to over fitting, while a low learning rate can lead to underfitting. i.e. have to maintain correct learning rate to get correct results.

Learning Paradigm               ::              Libraries
    - Online Learning	        :: River, Vowpal Wabbit, scikit-multiflow
    - Batch Learning	        :: Scikit-learn, TensorFlow, PyTorch, Keras, XGBoost, LightGBM, CatBoost, Fastai, H2O.ai
    - Reinforcement Learning    :: Stable-Baselines3, RLlib, Dopamine, Vowpal Wabbit (contextual bandits), OpenAI Gym (envs)
    - AutoML                    :: Auto-sklearn, AutoKeras, TPOT, H2O AutoML

>> Types of ML based Learning:
    1. Instance-based learning: The algorithm learns from individual instances of data. (e.g. K-Nearest Neighbors)
    2. Model-based learning: The algorithm learns from a model of the data. (e.g. Bayesian Networks)

>> Challenges in ML:
    1. Data Collection
        (Fetch DATA from API or Web Scrapping)
    2. Insufficient Data/Labelled data : 
    3. Non representative Data
        Sample Noise: means the data is not representative of the population.
        Sample Bias: means the data is biased towards a particular group.
    4. poor quality data 
    5. irrelevant features : means the features are not relevant to the problem.
    6. overfitting*** : model is too complex and fits the noise in the training data. (--> i.e basically ML model just learn the data without understanding that results in poor performance with new set of data)
    7. underfitting : model is too simple and fails to capture the underlying patterns in the data.
    8. Software integration
    9. offline Learning/ Deployment
    10. cost involved

>> ML Development life cycle:
    Set of guideline from problem definition to deployment of model. (From idea to product) 
    1. Frame the problem
    2. Gathering Data
        Tools:  using CSV 
                API calling
                Web Scraping
                from large database -> Data warehousing (ETL: extract tranform load) -> data Fetch
                Data fetch using Clusturing
    3. Data preprocessing -> data cleaning (i.e. remove duplicate, remove missing values, remove outliers, scaling or standerdization)
        Probolems: (unclean data)  
                    noisy data
                    outlier data
                    missing data
                    irrelevant data
                    data normalization
                    uncompetable data
    4. Exploratory Data Analysis (EDA) -> data visualization (i.e. bar chart, scatter plot, histogram) univarient/bivarient and find correlation between data
    5. Feature engineering and selection (input means feature) 
    6. Model training, Evaluation and selection + Ensemble Learning (Merge multiple models to boost up performance)
    7. Model deployment -> model to binary file(using tools like pickle) then convert into API(returns JSON).  
    8. Model testing
    9. Optimize -> Scaling the model    
                Necessary steps:
                    Model Backup
                    Data Backup
                    Load Balancing
                    Re-train model over a period of time

Job role:
    Search on anglelist, wellfound(for startUps) or any other job platform.
    1. Data Scientist
    2. Machine Learning Engineer
    3. Data Engineer
    4. Data Analyst

https://github.com/LeCoupa/awesome-cheatsheets/tree/master